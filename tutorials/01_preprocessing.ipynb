{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mvTCR Preprocessing\n",
    "mvTCR uses a specific format to handle single-cell data, which is based on AnnData objects. If not otherwise stated, we follow the speficition from Scanpy [1] and Scirpy [2]. However, we need some additional information to utilize all functions of mvTCR. In this notebook, we introduce the mvTCR preprocessing pipeline, which adds the required information to the corresponding place in the AnnData object.\n",
    "\n",
    "All experiments in our paper where conducted on Datasets:\n",
    "- after Quality Control (cell filtering, doublet detection, ...)\n",
    "- with normalized and log+1 transformed count data\n",
    "\n",
    "The pipeline assumes that these steps have already been performed. For further reference, please see Luecken et al [3].\n",
    "\n",
    "If you know what you are doing: different normalization, log-stabilizing transformations, etc. can also be used, but need to be handled with care!\n",
    "\n",
    "\n",
    "[1] Wolf, F. A., Angerer, P. & Theis, F. J. Scanpy: large-scale single-cell gene expression data analysis. Genome biology 19, 1–5 (2018).\n",
    "\n",
    "[2] Sturm, G. et al. Scirpy: a scanpy extension for analyzing single-cell t-cell receptor-sequencing data. Bioinformatics 36, 4817–4818 (2020).\n",
    "\n",
    "[3] Luecken, M. D. & Theis, F. J. Current best practices in single-cell rna-seq analysis: a tutorial.\n",
    "Molecular systems biology 15, e8746 (2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisits\n",
    "\n",
    "The preprocessing pipeline is showcased on the dataset from Stephenson et al. [4], which can be readily downloaded from:\n",
    "\n",
    "- https://covid19.cog.sanger.ac.uk/submissions/release1/haniffa21.processed.h5ad\n",
    "- https://www.ebi.ac.uk/biostudies/files/E-MTAB-10026/TCR_merged-Updated.tsv\n",
    "\n",
    "and is already quality-controled. \n",
    "\n",
    "[4] Stephenson, E. et al. Single-cell multi-omics analysis of the immune response in covid-19. Nature medicine 27, 904–916 (2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The mvTCR preprocessing pipeline is taylored for mvTCR-usage and handles the encoding of clonotypes and conditional variables in the required format. However, it is necessary that the adata object is already log-normalized, subsetted to highly variable genes and contains scirpy-encoded TCR information. We demonstrate these steps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jan\\.conda\\envs\\mvtcr_preprocheck\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import scirpy as ir\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gex = '../data/Haniffa/haniffa21.processed.h5ad'\n",
    "path_tcr = '../data/Haniffa/TCR_merged-Updated'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the transcriptome data. To speed up runtime, we will downsample the data to two patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read(path_gex)\n",
    "\n",
    "selected_patients = ['AP1', 'CV0062']\n",
    "adata = adata[adata.obs['patient_id'].isin(selected_patients)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, we take the raw expression counts matrix, total-count normalize it to 10,000 reads per cell to correct for differences in library-size, and logarithmize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 2. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[[1.1596017 0.        0.        0.        0.        1.1596017 0.\n",
      "  0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        1.52811   0.\n",
      "  0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.       ]\n",
      " [0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.       ]]\n"
     ]
    }
   ],
   "source": [
    "adata.X = adata.layers['raw']\n",
    "print(adata.X[0:4,11:20].toarray())\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "print(adata.X[0:4,11:20].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep the most informative genes, we subset our matrix to the 5000 highest-variable genes. This number can be changed based on the expected variation, and noisy or technical-artifact related genes can be excluded based on prior knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before:  (8811, 24929)\n",
      "Shape after:  (8811, 5000)\n"
     ]
    }
   ],
   "source": [
    "print('Shape before: ', adata.shape)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=5000)\n",
    "adata = adata[:, adata.var['highly_variable']]\n",
    "print('Shape after: ', adata.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we add the required TCR information as scirpy formatted covariates in the obs matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jan\\.conda\\envs\\mvtcr_preprocheck\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3266: DtypeWarning: Columns (38,39,40) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_tcr = pd.read_csv(f'{path_tcr}.tsv', sep='\\t')\n",
    "df_tcr['barcode'] = df_tcr.pop('CellID') # change cell IDs column name to \"barcode\"\n",
    "df_tcr = df_tcr[df_tcr['study_id'].isin(selected_patients)] # keep only selected patients\n",
    "df_tcr.to_csv(f'{path_tcr}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Non-standard locus name ignored: Multi \n",
      "c:\\Users\\Jan\\.conda\\envs\\mvtcr_preprocheck\\lib\\site-packages\\scirpy\\io\\_convert_anndata.py:81: FutureWarning: X.dtype being converted to np.float32 from float64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "  adata = AnnData(obs=ir_df, X=np.empty([ir_df.shape[0], 0]))\n"
     ]
    }
   ],
   "source": [
    "adata_tcr = ir.io.read_10x_vdj(f'{path_tcr}.csv') # load with scirpy\n",
    "ir.pp.merge_with_ir(adata, adata_tcr)\n",
    "del adata_tcr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mvTCR requires paired data between TCR and GEX. Therefore, we remove all samples without a TRA or TRB CDR3 region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8811\n",
      "4227\n"
     ]
    }
   ],
   "source": [
    "print(len(adata))\n",
    "adata = adata[~(adata.obs['IR_VDJ_1_junction_aa'].isna() | adata.obs['IR_VJ_1_junction_aa'].isna())].copy()\n",
    "print(len(adata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mvTCR preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#This is only needed if you have not installed mvTCR in your conda environment and want to import the functions locally.\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tcr_embedding.utils_preprocessing import Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All-in-one Pipeline\n",
    "\n",
    "After we have a fitting dataset containing scirpy-encoded TCR information and expression data we can use mvTCR's preprocessing methods to further bring our data into shape.\n",
    "The preprocessing pipeline is the fast way to do that your data. \n",
    "\n",
    "This features (in order):\n",
    "\n",
    "- Checks for:\n",
    "    - Normalization & log transformation checks (experimental)\n",
    "    - \"Reasonable\" number of highly variable genes check (500 < n < 5000)\n",
    "    - Scirpy VDJ gene usage information check\n",
    "- Encoding of clonotypes\n",
    "- Encoding of TCR\n",
    "- One-Hot encoding of conditional variables\n",
    "- Group-shuffle-splits (into train & validation datasets)\n",
    "\n",
    "The required parameters and expected outputs of each step are explained in detail in the piece by piece preprocessing section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Only highly-variable genes found in adata. Make sure they are properly normalized before proceeding!\n",
      "100%|██████████| 4049/4049 [00:04<00:00, 847.41it/s]\n"
     ]
    }
   ],
   "source": [
    "Preprocessing.preprocessing_pipeline(adata, \n",
    "                                     clonotype_key_added='clonotype', \n",
    "                                     column_cdr3a='IR_VJ_1_junction_aa', \n",
    "                                     column_cdr3b='IR_VDJ_1_junction_aa',\n",
    "                                     cond_vars=['patient_id'],\n",
    "                                     group_col='clonotype', \n",
    "                                     val_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    3384\n",
       "val       843\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.set.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Piece by Piece Preprocessing\n",
    "\n",
    "All the features inside the pipeline can be executed seperately as well, to perform a step-by-setp preprocessing or only specific methods.\n",
    "\n",
    "Make sure to freshly load the data if you have used the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if adata is in a mvTCR compatible shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Only highly-variable genes found in adata. Make sure they are properly normalized before proceeding!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preprocessing.check_if_valid_adata(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding clonotypes with Scirpy\n",
    "\n",
    "For training the shared embedding, we advise oversampling rare clonotypes. This avoids the model overfitting to few selected TCR sequences from highly expanded clonotypes. Therefore, we need to add a clonotype label to adata.obs. Here, we define a unique clonotype via Scirpy as having exactly the same CDR3 sequence in TRA and TRB chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4049/4049 [00:03<00:00, 1202.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2251    32\n",
       "2207    25\n",
       "2527     8\n",
       "326      7\n",
       "3277     7\n",
       "        ..\n",
       "1898     1\n",
       "185      1\n",
       "3797     1\n",
       "2199     1\n",
       "2421     1\n",
       "Name: clonotype, Length: 4049, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preprocessing.encode_clonotypes(adata, key_added='clonotype')\n",
    "\n",
    "adata.obs.clonotype.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding TCR encoding\n",
    "\n",
    "Next, we encode the TCR sequence numerically to adata.obsm. Here, we need to provide the name of the column storing the CDR3a and CDR3b. Additionally, we need to specificy the padding paremter (which if set to None uses the maximal CDR3 sequence length as default). If you plan to add new data in the future via a pretrained model, you might want to add some safety margin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing.encode_tcr(adata, column_cdr3a='IR_VJ_1_junction_aa', column_cdr3b='IR_VDJ_1_junction_aa', alpha_label_col='alpha_seq', alpha_length_col='alpha_len', beta_label_col='beta_seq', beta_length_col='beta_len', pad=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  1, 16, ...,  0,  0,  0],\n",
       "       [ 2, 16,  1, ...,  0,  0,  0],\n",
       "       [ 2,  1, 17, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 2,  1, 16, ...,  0,  0,  0],\n",
       "       [ 2,  1, 16, ...,  0,  0,  0],\n",
       "       [ 2,  1, 16, ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obsm['beta_seq']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding conditional variables\n",
    "\n",
    "Conditioning your model partially removes the effect from a specified condition. We can add conditional variables for e.g. donor, to avoid batch effects over multiple samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing.encode_conditional_var(adata, column_id='patient_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obsm['patient_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and validation splits\n",
    "\n",
    "The splitting improves the data spliting into training and validation sets by two properties:\n",
    "- Stratified splitting: balance a label of interest (normally a variable to be predicted, e.g. antigen specificity) so the label distribution is roughly the same in both sets.\n",
    "- Avoid training data leakage into validation: used for clonotypes, to ensure that each clonotype is observed only during training or validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 106.85it/s]\n"
     ]
    }
   ],
   "source": [
    "train, val = Preprocessing.stratified_group_shuffle_split(adata.obs, stratify_col='full_clustering', group_col='clonotype', val_split=0.2, random_seed=42)\n",
    "\n",
    "adata.obs['set'] = 'train'\n",
    "adata.obs.loc[val.index, 'set'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    3357\n",
       "val       870\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.set.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively group splitting is available by itself with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtrain, gval = Preprocessing.group_shuffle_split(adata, group_col='clonotype', val_split=0.2, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs['set'] = 'train'\n",
    "adata.obs.loc[gval.obs.index, 'set'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    3384\n",
       "val       843\n",
       "Name: set, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs.set.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finish. You are all set and done to use mvTCR! Save your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = '../data/preprocessed/haniffa_test.h5ad'\n",
    "adata.write_h5ad(path_out, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvTCR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
